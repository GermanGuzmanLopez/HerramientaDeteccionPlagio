Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. This technology has the potential to revolutionize how humans interact with machines by enabling more intuitive and responsive interfaces. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. Such applications are crucial for creating more natural and effective human-robot interactions. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. This approach not only enhances user experience but also personalizes interactions based on emotional context. As a result, new emotion models require more investigation as existing ones struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. CNNs are particularly well-suited for this task due to their ability to capture complex patterns in visual data. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. This system demonstrates the practical application of advanced AI techniques in enhancing everyday experiences. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. This combination allowed for a robust evaluation of model performance across different data sources. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. These predictions are critical for tailoring responses and interactions based on the user's emotional state. The proposed system can be utilized in different places where real-time facial recognition plays an important role. Such systems can significantly improve user interactions in sectors ranging from customer service to personal entertainment.