The concept of Artificial General Intelligence (AGI) revolves around the notion that a future hypothetical agent will emerge from advancements in artificial intelligence (AI), eventually surpassing the brightest and most talented human intellects. This idea has been present since the inception of AI development. Over time, various scenarios depicting how such AI might interact with humans have been explored in both fiction and research. This paper examines the current state of AI advancements and how the rapid release of impressive new AI methods (capable of deceiving humans, excelling at tasks previously deemed impossible for AI, and disrupting the job market) has sparked concerns that AGI might arrive sooner than anticipated. Specifically, we analyze three distinct families of modern AIs to argue that deep neural networks, which form the foundation of nearly all current AI methods, are unlikely candidates for the emergence of AGI due to their inherent limitations. Consequently, the threat posed by the recent AI race is not AGI itself but rather the limitations, applications, and lack of regulations surrounding our existing models and algorithms.