This paper presented a method for providing explainability in the integration of artificial intelligence (AI) and data mining techniques when dealing with meteorological prediction. Explainable artificial intelligence (XAI) referred to the transparency of AI systems in providing explanations for their predictions and decision-making processes, and contributed to improving prediction accuracy and enhancing trust in AI systems. The focus of this paper relied on the interpretability challenges in ordinal classification problems within weather forecasting. Ordinal classification involved predicting weather phenomena with ordered classes, such as temperature ranges, wind speed, precipitation levels, and others. To address this challenge, a novel and general explicable forecasting framework, that combined inductive rules and fuzzy logic, was proposed in this work. Inductive rules, derived from historical weather data, provided a logical and interpretable basis for forecasting, while fuzzy logic handled the uncertainty and imprecision in the weather data. The system predicted a set of probabilities that the incoming sample belonged to each considered class. Moreover, it allowed the expert decision-making process to be strengthened by relying on the transparency and physical explainability of the model, and not only on the output of a black-box algorithm. The proposed framework was evaluated using two real-world weather databases related to wind speed and low-visibility events due to fog. The results were compared to both ML classifiers and specific methods for ordinal classification problems, achieving very competitive results in terms of ordinal performance metrics while offering a higher level of explainability and transparency compared to existing approaches.